{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14381ed-8da4-4748-b1d1-03136979c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.sql(\"DROP table bootcamp.matches_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb01d98c-8282-49e0-803c-c442feafdd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://1ea50b4f30b2:4041\n",
       "SparkContext available as 'sc' (version = 3.5.5, master = local[*], app id = local-1755388306260)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.functions.col\n",
       "import org.apache.spark.storage.StorageLevel\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@7c29127a\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions.{col}\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"IcebergTableManagement\") \n",
    "  .config(\"spark.executor.memory\", \"4g\")\n",
    "  .config(\"spark.driver.memory\", \"4g\")\n",
    "  .config(\"spark.sql.shuffle.partitions\", \"200\") // Fine for large datasets\n",
    "  .config(\"spark.sql.files.maxPartitionBytes\", \"134217728\") // Optional: 128 MB is default\n",
    "  .config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\") // Optional: Disable broadcast join\n",
    "  .config(\"spark.dynamicAllocation.enabled\", \"true\") // Helps with resource allocation\n",
    "  .config(\"spark.dynamicAllocation.minExecutors\", \"1\") // Ensure minimum resources\n",
    "  .config(\"spark.dynamicAllocation.maxExecutors\", \"50\") // Scalable resource allocation\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de6d13b-d7e4-4065-a0dd-27f4c8621d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://1ea50b4f30b2:4045\n",
       "SparkContext available as 'sc' (version = 3.5.5, master = local[*], app id = local-1755367894001)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+-------------------+\n",
      "|            match_id|is_team_game|         playlist_id|    completion_date|\n",
      "+--------------------+------------+--------------------+-------------------+\n",
      "|d6f3478c-255f-43d...|        true|892189e9-d712-4bd...|2016-08-28 00:00:00|\n",
      "|2b7b17c4-716f-42d...|        true|355dc154-9809-4ed...|2016-02-25 00:00:00|\n",
      "|821762ff-49b7-4a7...|        true|f72e0ef0-7c4a-430...|2016-02-25 00:00:00|\n",
      "|d683cc2b-eef6-442...|        true|355dc154-9809-4ed...|2016-02-25 00:00:00|\n",
      "|383f4a85-eb1f-49d...|        true|355dc154-9809-4ed...|2016-02-25 00:00:00|\n",
      "|da4d676b-7e95-4f7...|        true|f72e0ef0-7c4a-430...|2016-02-25 00:00:00|\n",
      "|a1160c68-bbcb-4ab...|        true|f72e0ef0-7c4a-430...|2016-02-25 00:00:00|\n",
      "|c72bc126-4eba-4df...|        true|f72e0ef0-7c4a-430...|2016-02-25 00:00:00|\n",
      "|ab0f875b-0d43-4b9...|        true|355dc154-9809-4ed...|2016-02-25 00:00:00|\n",
      "|7958d054-1d78-4ff...|        true|355dc154-9809-4ed...|2016-02-25 00:00:00|\n",
      "|c6b3e32d-6d67-41e...|        true|f72e0ef0-7c4a-430...|2016-06-05 00:00:00|\n",
      "|7d701eb9-721c-4a3...|        true|f72e0ef0-7c4a-430...|2016-06-05 00:00:00|\n",
      "|060cf261-5ee4-403...|        true|f72e0ef0-7c4a-430...|2016-05-26 00:00:00|\n",
      "|e597cf8b-dcb9-4da...|        true|f72e0ef0-7c4a-430...|2016-05-26 00:00:00|\n",
      "|f68a6ffb-29ea-451...|        true|f72e0ef0-7c4a-430...|2016-05-26 00:00:00|\n",
      "|3184df84-fdca-418...|        true|f72e0ef0-7c4a-430...|2016-05-26 00:00:00|\n",
      "|63bc8c47-baa6-4db...|        true|f72e0ef0-7c4a-430...|2016-05-26 00:00:00|\n",
      "|c1d6bd7c-06b3-4f1...|        true|f72e0ef0-7c4a-430...|2016-05-26 00:00:00|\n",
      "|6bd6d5ac-6a76-45a...|        true|892189e9-d712-4bd...|2016-05-26 00:00:00|\n",
      "|0a5d609f-a39b-4dd...|        true|c98949ae-60a8-43d...|2016-05-26 00:00:00|\n",
      "+--------------------+------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.functions.col\n",
       "import org.apache.spark.storage.StorageLevel\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@6bdbcfff\n",
       "matchesBucketedselect: org.apache.spark.sql.DataFrame = [match_id: string, mapid: string ... 8 more fields]\n",
       "distinctDates: Array[org.apache.spark.sql.Row] = Array([2016-03-13 00:00:00.0], [2016-03-11 00:00:00.0], [2016-03-10 00:00:00.0], [2016-01-30 00:00:00.0], [2016-03-27 00:00:00.0], [2016-04-10 00:00:00.0], [2016-01-18 00:00:00.0], [2016-02-01 00:00:00.0], [2015-12-14 00:00:00.0], [2016-02-03 00:00:00.0], [2016-04-30 00:00:00.0], [2016-03-05 00:00:00.0], [2016-04-15 00:00:00.0], [2016-05-21 00:00:00.0], [2015-10-31 00:00:00.0], [2016-01-22 00:00:00.0], [2016-02-09 00:00:00...\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "val matchesBucketedselect = spark.read.option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"/home/iceberg/data/matches.csv\")\n",
    "\n",
    "// Get distinct completion dates\n",
    "val distinctDates = matchesBucketedselect.select(\"completion_date\").distinct().collect()\n",
    "\n",
    "// Create the Iceberg table if it doesn't exist\n",
    "spark.sql(\"\"\"DROP TABLE IF EXISTS bootcamp.matches_bucketed\"\"\")\n",
    "val bucketedDDL = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.matches_bucketed (\n",
    "    match_id STRING,\n",
    "    is_team_game BOOLEAN,\n",
    "    playlist_id STRING,\n",
    "    completion_date TIMESTAMP\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (completion_date, bucket(16, match_id))\n",
    "\"\"\"\n",
    "spark.sql(bucketedDDL)\n",
    "\n",
    "// Process data in chunks based on completion_date\n",
    "distinctDates.foreach { row =>\n",
    "  val date = row.getAs[java.sql.Timestamp](\"completion_date\")\n",
    "  val filteredMatches = matchesBucketedselect.filter(col(\"completion_date\") === date)\n",
    "  \n",
    "  // Repartition and persist the filtered data\n",
    "  val optimizedMatches = filteredMatches\n",
    "    .select($\"match_id\", $\"is_team_game\", $\"playlist_id\", $\"completion_date\")\n",
    "    .repartition(16, $\"match_id\")\n",
    "    .persist(StorageLevel.MEMORY_AND_DISK)\n",
    "    \n",
    "  optimizedMatches.write\n",
    "    .mode(\"append\")\n",
    "    .bucketBy(16, \"match_id\")\n",
    "    .partitionBy(\"completion_date\")\n",
    "    .saveAsTable(\"bootcamp.matches_bucketed\")\n",
    "}\n",
    "\n",
    "// Verify the data in the table\n",
    "val result = spark.sql(\"SELECT * FROM bootcamp.matches_bucketed\")\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5325e4c-4322-40a1-af7c-e5cf71950901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|num_files|\n",
      "+---------+\n",
      "|     3665|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"SELECT COUNT(1) as num_files FROM bootcamp.matches_bucketed.files\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf36a156-9793-4237-b84a-a1a017973198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matchDetailsBucketed: org.apache.spark.sql.DataFrame = [match_id: string, player_gamertag: string ... 34 more fields]\n",
       "bucketedDetailsDDL: String =\n",
       "\"\n",
       " CREATE TABLE IF NOT EXISTS bootcamp.match_details_bucketed (\n",
       "     match_id STRING,\n",
       "     player_gamertag STRING,\n",
       "     player_total_kills INTEGER,\n",
       "     player_total_deaths INTEGER\n",
       " )\n",
       " USING iceberg\n",
       " PARTITIONED BY (bucket(16, match_id));\n",
       " \"\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val matchDetailsBucketed =  spark.read.option(\"header\", \"true\")\n",
    "                        .option(\"inferSchema\", \"true\")\n",
    "                        .csv(\"/home/iceberg/data/match_details.csv\")\n",
    "\n",
    "val bucketedDetailsDDL = \"\"\"\n",
    " CREATE TABLE IF NOT EXISTS bootcamp.match_details_bucketed (\n",
    "     match_id STRING,\n",
    "     player_gamertag STRING,\n",
    "     player_total_kills INTEGER,\n",
    "     player_total_deaths INTEGER\n",
    " )\n",
    " USING iceberg\n",
    " PARTITIONED BY (bucket(16, match_id));\n",
    " \"\"\"\n",
    "spark.sql(bucketedDetailsDDL)\n",
    "\n",
    "matchDetailsBucketed.select(\n",
    "    $\"match_id\", $\"player_gamertag\", $\"player_total_kills\", $\"player_total_deaths\")\n",
    "    .write.mode(\"append\")\n",
    "    .bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.match_details_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fb724a5-2b3f-423f-8c1c-638ff77a5473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+------------------+-------------------+\n",
      "|            match_id|player_gamertag|player_total_kills|player_total_deaths|\n",
      "+--------------------+---------------+------------------+-------------------+\n",
      "|f8852913-2ccf-46f...|    OneWingKing|                 7|                  6|\n",
      "|155cfd23-4f97-4f1...|   BigChubSmith|                15|                 11|\n",
      "|155cfd23-4f97-4f1...|  JakeWilson801|                18|                  9|\n",
      "|155cfd23-4f97-4f1...|      taterbase|                 1|                 12|\n",
      "|155cfd23-4f97-4f1...| BeyondHumanx39|                13|                 14|\n",
      "|155cfd23-4f97-4f1...|   Twinsnakes05|                16|                 11|\n",
      "|155cfd23-4f97-4f1...|  Maverick62011|                 9|                 14|\n",
      "|155cfd23-4f97-4f1...|       EcZachly|                16|                 16|\n",
      "|155cfd23-4f97-4f1...|      WhiteSpic|                10|                 12|\n",
      "|b8d81721-befb-427...|  JakeWilson801|                16|                  9|\n",
      "|b8d81721-befb-427...|      taterbase|                 3|                 13|\n",
      "|b8d81721-befb-427...|       EcZachly|                19|                 14|\n",
      "|b8d81721-befb-427...|     cLaPPeD xo|                11|                 15|\n",
      "|b8d81721-befb-427...|        Nawsked|                12|                 14|\n",
      "|b8d81721-befb-427...|        iVaughn|                14|                 12|\n",
      "|b8d81721-befb-427...|     Roy Dossey|                13|                 11|\n",
      "|b8d81721-befb-427...|     Confustion|                11|                 12|\n",
      "|c0c3daed-ad92-48e...|        SnipedI|                 6|                  6|\n",
      "|c0c3daed-ad92-48e...|       Clappage|                 9|                  4|\n",
      "|c0c3daed-ad92-48e...|       EcZachly|                 8|                  5|\n",
      "+--------------------+---------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "result: org.apache.spark.sql.DataFrame = [match_id: string, player_gamertag: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Verify the data in the table\n",
    "val result = spark.sql(\"SELECT * FROM bootcamp.match_details_bucketed\")\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c3e425-d6e2-4e07-b903-50e2d4b331d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|num_files|\n",
      "+---------+\n",
      "|       16|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(1) as num_files FROM bootcamp.match_details_bucketed.files\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f39962-9faf-41d6-bb5c-3c36e93f2c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- SortMergeJoin [match_id#37221], [match_id#37225], Inner\n",
      "   :- Sort [match_id#37221 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(match_id#37221, 200), ENSURE_REQUIREMENTS, [plan_id=15575]\n",
      "   :     +- BatchScan demo.bootcamp.match_details_bucketed[match_id#37221, player_gamertag#37222, player_total_kills#37223, player_total_deaths#37224] demo.bootcamp.match_details_bucketed (branch=null) [filters=match_id IS NOT NULL, groupedBy=] RuntimeFilters: []\n",
      "   +- Sort [match_id#37225 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(match_id#37225, 200), ENSURE_REQUIREMENTS, [plan_id=15576]\n",
      "         +- BatchScan demo.bootcamp.matches_bucketed[match_id#37225, is_team_game#37226, playlist_id#37227, completion_date#37228] demo.bootcamp.matches_bucketed (branch=null) [filters=completion_date IS NOT NULL, completion_date = 1451606400000000, match_id IS NOT NULL, groupedBy=] RuntimeFilters: []\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- SortMergeJoin [match_id#37066], [match_id#17], Inner\n",
      "   :- Sort [match_id#37066 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(match_id#37066, 200), ENSURE_REQUIREMENTS, [plan_id=15602]\n",
      "   :     +- Filter isnotnull(match_id#37066)\n",
      "   :        +- FileScan csv [match_id#37066,player_gamertag#37067,previous_spartan_rank#37068,spartan_rank#37069,previous_total_xp#37070,total_xp#37071,previous_csr_tier#37072,previous_csr_designation#37073,previous_csr#37074,previous_csr_percent_to_next_tier#37075,previous_csr_rank#37076,current_csr_tier#37077,current_csr_designation#37078,current_csr#37079,current_csr_percent_to_next_tier#37080,current_csr_rank#37081,player_rank_on_team#37082,player_finished#37083,player_average_life#37084,player_total_kills#37085,player_total_headshots#37086,player_total_weapon_damage#37087,player_total_shots_landed#37088,player_total_melee_kills#37089,... 12 more fields] Batched: false, DataFilters: [isnotnull(match_id#37066)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/iceberg/data/match_details.csv], PartitionFilters: [], PushedFilters: [IsNotNull(match_id)], ReadSchema: struct<match_id:string,player_gamertag:string,previous_spartan_rank:int,spartan_rank:int,previous...\n",
      "   +- Sort [match_id#17 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(match_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=15603]\n",
      "         +- Filter isnotnull(match_id#17)\n",
      "            +- FileScan csv [match_id#17,mapid#18,is_team_game#19,playlist_id#20,game_variant_id#21,is_match_over#22,completion_date#23,match_duration#24,game_mode#25,map_variant_id#26] Batched: false, DataFilters: [isnotnull(match_id#17)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/iceberg/data/matches.csv], PartitionFilters: [], PushedFilters: [IsNotNull(match_id)], ReadSchema: struct<match_id:string,mapid:string,is_team_game:boolean,playlist_id:string,game_variant_id:strin...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "\n",
    "matchesBucketedselect.createOrReplaceTempView(\"matches\")\n",
    "matchDetailsBucketed.createOrReplaceTempView(\"match_details\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM bootcamp.match_details_bucketed mdb JOIN bootcamp.matches_bucketed md \n",
    "    ON mdb.match_id = md.match_id\n",
    "    AND md.completion_date = DATE('2016-01-01')\n",
    "        \n",
    "\"\"\").explain()\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM match_details mdb JOIN matches md ON mdb.match_id = md.match_id\n",
    "        \n",
    "\"\"\").explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd2d4ca-ff38-412b-b10e-5e29716f9a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
