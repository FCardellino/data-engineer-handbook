{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee906429-59d5-47d0-a4bd-4d2cc1097087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.functions.col\n",
       "import org.apache.spark.storage.StorageLevel\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@61136eaa\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions.{col}\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "\n",
    "//CREATE AND CONFIGURE SPARK SESSION\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"SparkFundamentalsWeekHW\") \n",
    "  .config(\"spark.executor.memory\", \"4g\")\n",
    "  .config(\"spark.driver.memory\", \"4g\")\n",
    "  .config(\"spark.sql.shuffle.partitions\", \"200\") // Fine for large datasets\n",
    "  .config(\"spark.sql.files.maxPartitionBytes\", \"134217728\") // Optional: 128 MB is default\n",
    "  .config(\"spark.dynamicAllocation.enabled\", \"true\") // Helps with resource allocation\n",
    "  .config(\"spark.dynamicAllocation.minExecutors\", \"1\") // Ensure minimum resources\n",
    "  .config(\"spark.dynamicAllocation.maxExecutors\", \"50\") // Scalable resource allocation\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82c30411-b839-463c-b597-1a9feab0136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "//TASK 1: Disabled automatic broadcast join with spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "\n",
    "//Disabled automatic broadcast join\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "//END OF TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6f0df4b-ec3b-437b-9bc4-a7d98ae816a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medalsSelected: org.apache.spark.sql.DataFrame = [medal_id: bigint, sprite_uri: string ... 10 more fields]\n",
       "mapsSelected: org.apache.spark.sql.DataFrame = [mapid: string, name: string ... 1 more field]\n",
       "matchesSelected: org.apache.spark.sql.DataFrame = [match_id: string, mapid: string ... 8 more fields]\n",
       "matchDetailsSelected: org.apache.spark.sql.DataFrame = [match_id: string, player_gamertag: string ... 34 more fields]\n",
       "medalsMatchesPlayersSelected: org.apache.spark.sql.DataFrame = [match_id: string, player_gamertag: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//TASK 2: Explicitly broadcast JOINs medals and maps\n",
    "//SAVE DATA INTO VARIABLES \n",
    "val medalsSelected = spark.read.option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"/home/iceberg/data/medals.csv\")\n",
    "val mapsSelected = spark.read.option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"/home/iceberg/data/maps.csv\")\n",
    "val matchesSelected = spark.read.option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"/home/iceberg/data/matches.csv\")\n",
    "val matchDetailsSelected = spark.read.option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"/home/iceberg/data/match_details.csv\")\n",
    "val medalsMatchesPlayersSelected = spark.read.option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"/home/iceberg/data/medals_matches_players.csv\")\n",
    "\n",
    "//CREATE TEMP VIEWS FOR EXPLICIT BRODCAST JOIN\n",
    "medalsSelected.createOrReplaceTempView(\"medals\")\n",
    "mapsSelected.createOrReplaceTempView(\"maps\")\n",
    "matchesSelected.createOrReplaceTempView(\"matches\")\n",
    "medalsMatchesPlayersSelected.createOrReplaceTempView(\"medals_matches_players\")\n",
    "\n",
    "//DO AND SAVE EXPLICIT BROADCAST INTO VARIABLEs\n",
    "val explicitBroadcastMedals = medalsMatchesPlayersSelected.as(\"mmp\")\n",
    "                                                          .join(broadcast(medalsSelected).as(\"me\"),$\"mmp.medal_id\" === $\"me.medal_id\")\n",
    "                                                          .select($\"mmp.*\",$\"me.classification\")\n",
    "val explicitBroadcastMaps = matchesSelected.as(\"m\")\n",
    "                                           .join(broadcast(mapsSelected).as(\"ma\"),$\"m.mapid\" === $\"ma.mapid\")\n",
    "                                           .select($\"m.*\",$\"ma.name\")\n",
    "\n",
    "//END OF TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "962a428b-963a-4a23-a770-4908bd4e6ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bucketedDDL: String =\n",
       "\"\n",
       "CREATE TABLE IF NOT EXISTS bootcamp.medals_matches_players_bucketed (\n",
       "     match_id STRING,\n",
       "     player_gamertag STRING,\n",
       "     medal_id STRING,\n",
       "     count INTEGER,\n",
       "     classification STRING\n",
       " )\n",
       " USING iceberg\n",
       " PARTITIONED BY (bucket(16, match_id));\n",
       " \"\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//TASK 3: Bucket join match_details, matches, and medal_matches_players on match_id with 16 buckets\n",
    "\n",
    "//CREATE TABLES WITH BUCKETS AND SAVE BUCKETED DATA\n",
    "//CREATE TABLE medals_matches_players_bucketed\n",
    "spark.sql(\"\"\"DROP TABLE IF EXISTS bootcamp.medals_matches_players_bucketed\"\"\")\n",
    "val bucketedDDL = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.medals_matches_players_bucketed (\n",
    "     match_id STRING,\n",
    "     player_gamertag STRING,\n",
    "     medal_id STRING,\n",
    "     count INTEGER,\n",
    "     classification STRING\n",
    " )\n",
    " USING iceberg\n",
    " PARTITIONED BY (bucket(16, match_id));\n",
    " \"\"\"\n",
    "spark.sql(bucketedDDL)\n",
    "\n",
    "//LOAD DATA INTO BUCKETED TABLE\n",
    "explicitBroadcastMedals.select(\n",
    "    $\"match_id\", $\"player_gamertag\", $\"medal_id\", $\"count\", $\"classification\"\n",
    "    )\n",
    "    .write.mode(\"append\")\n",
    "    .bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.medals_matches_players_bucketed\")\n",
    "\n",
    "//CREATE TABLE matches_maps_bucketed\n",
    "// Get distinct completion dates\n",
    "val distinctDates = matchesSelected.select(\"completion_date\").distinct().collect()\n",
    "\n",
    "spark.sql(\"\"\"DROP TABLE IF EXISTS bootcamp.matches_maps_bucketed\"\"\")\n",
    "val bucketedDDL = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.matches_maps_bucketed (\n",
    "     match_id STRING,\n",
    "     mapid STRING,\n",
    "     name STRING,\n",
    "     is_team_game BOOLEAN,\n",
    "     playlist_id STRING,\n",
    "     completion_date TIMESTAMP\n",
    " )\n",
    " USING iceberg\n",
    " PARTITIONED BY (completion_date,bucket(16, match_id));\n",
    " \"\"\"\n",
    "spark.sql(bucketedDDL)\n",
    "\n",
    "//LOAD DATA INTO BUCKETED TABLE\n",
    "// Process data in chunks based on completion_date\n",
    "distinctDates.foreach { row =>\n",
    "  val date = row.getAs[java.sql.Timestamp](\"completion_date\")\n",
    "  val filteredMatches = explicitBroadcastMaps.filter(col(\"completion_date\") === date)\n",
    "  \n",
    "  // Repartition and persist the filtered data\n",
    "  val optimizedMatches = filteredMatches\n",
    "    .select( $\"match_id\", $\"mapid\", $\"name\", $\"is_team_game\", $\"playlist_id\", $\"completion_date\")\n",
    "    .repartition(16, $\"match_id\")\n",
    "    .persist(StorageLevel.MEMORY_AND_DISK)\n",
    "    \n",
    "  optimizedMatches.write\n",
    "    .mode(\"append\")\n",
    "    .bucketBy(16, \"match_id\")\n",
    "    .partitionBy(\"completion_date\")\n",
    "    .saveAsTable(\"bootcamp.matches_maps_bucketed\")\n",
    "}\n",
    "\n",
    "\n",
    "//CREATE TABLE match_details_bucketed\n",
    "spark.sql(\"\"\"DROP TABLE IF EXISTS bootcamp.match_details_bucketed\"\"\")\n",
    "val bucketedDDL = \"\"\"\n",
    " CREATE TABLE IF NOT EXISTS bootcamp.match_details_bucketed (\n",
    "     match_id STRING,\n",
    "     player_gamertag STRING,\n",
    "     player_total_kills INTEGER,\n",
    "     player_total_deaths INTEGER\n",
    " )\n",
    " USING iceberg\n",
    " PARTITIONED BY (bucket(16, match_id));\n",
    " \"\"\"\n",
    "spark.sql(bucketedDDL)\n",
    "\n",
    "//LOAD DATA INTO BUCKETED TABLE\n",
    "matchDetailsSelected.select(\n",
    "    $\"match_id\", $\"player_gamertag\", $\"player_total_kills\", $\"player_total_deaths\")\n",
    "    .write.mode(\"append\")\n",
    "    .bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.match_details_bucketed\")\n",
    "\n",
    "\n",
    "//JOIN TABLES TO CREATE DATAFRAME\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "    SELECT \n",
    "         mmb.match_id,\n",
    "         mmb.mapid, \n",
    "         mmb.name as map_name, \n",
    "         mmb.is_team_game, \n",
    "         mmb.playlist_id, \n",
    "         mmb.completion_date,\n",
    "         mdb.player_gamertag, \n",
    "         mdb.player_total_kills, \n",
    "         mdb.player_total_deaths,\n",
    "         mmpb.medal_id\", \n",
    "         mmpb.count as medals_count,\n",
    "         mmpb.classification as medal_classification\n",
    "    FROM bootcamp.matches_maps_bucketed AS mmb\n",
    "    JOIN bootcamp.match_details_bucketed AS mdb ON mdb.match_id=mmb.match_id\n",
    "    JOIN bootcamp.medals_matches_players_bucketed AS mmpb ON mmpb.match_id=mmb.match_id\n",
    "\"\"\"\n",
    ").createOrReplaceTempView(\"filteredDF\")\n",
    "\n",
    "//END OF TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab25f7a2-b86a-4e7a-9995-371eb924967f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "players_avg_kills: org.apache.spark.sql.DataFrame = [match_id: string, player_gamertag: string ... 1 more field]\n"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//TASK 4: Aggregate the joined data frame to figure out the following questions\n",
    "\n",
    "//Which player averages the most kills per game?\n",
    "val players_avg_kills = spark.sql(\n",
    "\"\"\"\n",
    "    WITH deduplication as(\n",
    "    SELECT \n",
    "         match_id,\n",
    "         player_gamertag, \n",
    "         player_total_kills\n",
    "    FROM filteredDF\n",
    "    GROUP BY match_id,player_gamertag,player_total_kills)\n",
    "    SELECT \n",
    "        match_id,\n",
    "        player_gamertag,\n",
    "        sum(player_total_kills)/count(distinct match_id) as avg_kills_per_game\n",
    "    FROM deduplication\n",
    "    GROUP BY match_id,player_gamertag\n",
    "    ORDER BY sum(player_total_kills)/count(distinct match_id) desc\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "502cea84-33dc-46b3-9d96-69fbc42ce42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|         playlist_id|num_plays|\n",
      "+--------------------+---------+\n",
      "|f72e0ef0-7c4a-430...|  1565529|\n",
      "|780cc101-005c-4fc...|  1116002|\n",
      "|0bcf2be1-3168-4e4...|  1015496|\n",
      "|c98949ae-60a8-43d...|   824932|\n",
      "|2323b76a-db98-4e0...|   692342|\n",
      "|892189e9-d712-4bd...|   667670|\n",
      "|f27a65eb-2d11-496...|   167498|\n",
      "|355dc154-9809-4ed...|   140006|\n",
      "|d0766624-dbd7-453...|   138470|\n",
      "|bc0f8ad6-31e6-4a1...|   111073|\n",
      "|7b7e892c-d9b7-4b0...|    82723|\n",
      "|7385b4a1-86bf-4ae...|    76425|\n",
      "|f0c9ef9a-48bd-4b2...|    47813|\n",
      "|b5d5a242-ffa5-4d8...|    46411|\n",
      "|819eb188-1a1c-48b...|    39404|\n",
      "|d21c8381-26f1-4d6...|    37049|\n",
      "|4b12472e-2a06-423...|    28733|\n",
      "|5728f612-3f20-445...|    28543|\n",
      "|0504ca3c-de41-48f...|    22502|\n",
      "|88b7de19-113c-4be...|    15860|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "//Which playlist gets played the most?\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "    WITH playlist_played as(\n",
    "    SELECT \n",
    "         match_id,\n",
    "         playlist_id, \n",
    "         count(1) as playlist_count\n",
    "    FROM filteredDF\n",
    "    GROUP BY match_id,playlist_id)\n",
    "    SELECT \n",
    "        playlist_id,\n",
    "        sum(playlist_count) num_plays\n",
    "    FROM playlist_played\n",
    "    GROUP BY playlist_id\n",
    "    ORDER BY sum(playlist_count) desc\n",
    "\"\"\"\n",
    ").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9220cb33-4db8-4690-a2fb-db9ad8ec4d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+---------+\n",
      "|               mapid|      map_name|num_plays|\n",
      "+--------------------+--------------+---------+\n",
      "|c74c9d0f-f206-11e...|        Alpine|  1445545|\n",
      "|c7edbf0f-f206-11e...|Breakout Arena|  1435048|\n",
      "|c7805740-f206-11e...|       Glacier|   953278|\n",
      "|cdb934b0-f206-11e...|        Empire|   396305|\n",
      "|cb914b9e-f206-11e...|       The Rig|   309045|\n",
      "|ce1dc2de-f206-11e...|         Truth|   299736|\n",
      "|cebd854f-f206-11e...|      Coliseum|   298891|\n",
      "|caacb800-f206-11e...|         Plaza|   291540|\n",
      "|cd844200-f206-11e...|          Eden|   261162|\n",
      "|cc040aa1-f206-11e...|        Fathom|   256966|\n",
      "|cdee4e70-f206-11e...|        Regret|   244295|\n",
      "|c7b7baf0-f206-11e...|      Parallax|   204568|\n",
      "|ca737f8f-f206-11e...|    Overgrowth|   156631|\n",
      "|cbcea2c0-f206-11e...|      Riptide |   135375|\n",
      "|cc74f4e1-f206-11e...|          NULL|   132392|\n",
      "|ce89a40f-f206-11e...|          NULL|    65081|\n",
      "+--------------------+--------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Which map gets played the most?\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "    WITH maps_played as(\n",
    "    SELECT \n",
    "         match_id,\n",
    "         mapid,\n",
    "         map_name,\n",
    "         count(1) as map_count\n",
    "    FROM filteredDF\n",
    "    GROUP BY match_id,mapid,map_name\n",
    "    )\n",
    "    SELECT \n",
    "        mapid,\n",
    "        map_name,\n",
    "        sum(map_count) num_plays\n",
    "    FROM maps_played\n",
    "    GROUP BY  mapid,map_name\n",
    "    ORDER BY sum(map_count) desc\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6dcae887-aca6-497f-8644-be0dd8a60d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+----------+\n",
      "|               mapid|      map_name|medal_classification|num_medals|\n",
      "+--------------------+--------------+--------------------+----------+\n",
      "|c7805740-f206-11e...|       Glacier|        KillingSpree|        37|\n",
      "|c74c9d0f-f206-11e...|        Alpine|        KillingSpree|        21|\n",
      "|c7b7baf0-f206-11e...|      Parallax|        KillingSpree|        15|\n",
      "|cc74f4e1-f206-11e...|          NULL|        KillingSpree|        11|\n",
      "|cebd854f-f206-11e...|      Coliseum|        KillingSpree|        11|\n",
      "|cb914b9e-f206-11e...|       The Rig|        KillingSpree|        10|\n",
      "|ce1dc2de-f206-11e...|         Truth|        KillingSpree|        10|\n",
      "|cc040aa1-f206-11e...|        Fathom|        KillingSpree|        10|\n",
      "|cdee4e70-f206-11e...|        Regret|        KillingSpree|        10|\n",
      "|ce89a40f-f206-11e...|          NULL|        KillingSpree|        10|\n",
      "|cd844200-f206-11e...|          Eden|        KillingSpree|        10|\n",
      "|cdb934b0-f206-11e...|        Empire|        KillingSpree|        10|\n",
      "|caacb800-f206-11e...|         Plaza|        KillingSpree|         6|\n",
      "|cbcea2c0-f206-11e...|      Riptide |        KillingSpree|         6|\n",
      "|c7edbf0f-f206-11e...|Breakout Arena|        KillingSpree|         6|\n",
      "|ca737f8f-f206-11e...|    Overgrowth|        KillingSpree|         6|\n",
      "+--------------------+--------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Which map do players get the most Killing Spree medals on?\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "    WITH maps_and_medals as(\n",
    "    SELECT \n",
    "         mapid,\n",
    "         map_name,\n",
    "         medal_classification,\n",
    "         medals_count\n",
    "    FROM filteredDF\n",
    "    WHERE medal_classification='KillingSpree'\n",
    "    GROUP BY mapid,map_name,medal_classification,medals_count\n",
    "    )\n",
    "    SELECT \n",
    "         mapid,\n",
    "         map_name,\n",
    "         medal_classification,\n",
    "         sum(medals_count) num_medals\n",
    "    FROM maps_and_medals\n",
    "    GROUP BY  mapid,map_name,medal_classification\n",
    "    ORDER BY sum(medals_count) desc\n",
    "\"\"\"\n",
    ").show()\n",
    "//END OF TASK 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea941578-121a-406a-bff5-7af505408b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "//TASK 5: Try different .sortWithinPartitions to see which has the smallest data size\n",
    "\n",
    "//CREATE SORTED TABLE\n",
    "spark.sql(\"\"\"DROP TABLE IF EXISTS bootcamp.players_avg_kills\"\"\")\n",
    "val sortedDDL = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.players_avg_kills (\n",
    "    match_id STRING,\n",
    "    player_gamertag STRING,\n",
    "    avg_kills_per_game REAL\n",
    " )\n",
    " USING iceberg\n",
    " PARTITIONED BY (match_id));\n",
    " \"\"\"\n",
    "spark.sql(sortedDDL)\n",
    "//LOAD DATA INTO BUCKETED TABLE\n",
    "players_avg_kills.select(\n",
    "    $\"match_id\", $\"player_gamertag\", $\"avg_kills_per_game\")\n",
    "    .write.mode(\"append\")\n",
    "    .saveAsTable(\"bootcamp.players_avg_kills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0a714b4-f06f-4488-ab98-41089b1bb0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+\n",
      "|    size|num_files|sorted|\n",
      "+--------+---------+------+\n",
      "|10001308|     3665|sorted|\n",
      "+--------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT SUM(file_size_in_bytes) as size, COUNT(1) as num_files, 'sorted' \n",
    "FROM bootcamp.matches_maps_bucketed.files\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fb9d5-af0e-4130-b691-e30e49d2e85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a3cc471-d4cc-4010-bdcd-3e532728316b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res17: Array[String] = Array(match_id, mapid, is_team_game, playlist_id, game_variant_id, is_match_over, completion_date, match_duration, game_mode, map_variant_id)\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//spark.sql(\"\"\"SELECT * FROM medals me\"\"\").columns//medal_id,classification=KillingSpree\n",
    "//spark.sql(\"\"\"SELECT * FROM maps me\"\"\").columns//mapid,name\n",
    "//spark.sql(\"\"\"SELECT * FROM matches me\"\"\").columns//match_id,mapid,playlist_id,completion_date\n",
    "//spark.sql(\"\"\"SELECT * FROM match_details me\"\"\").columns//match_id,player_gamertag,player_total_kills\n",
    "//spark.sql(\"\"\"SELECT * FROM medals_matches_players me\"\"\").columns//match_id, player_gamertag, medal_id, count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
